---
title: "Distilling Causality from Correlation in Large-scale Omics Datasets"
author: "Robert Ness"
date: "September 3, 2015"
output: html_document
---

Causal inference – the task of uncovering regulatory relationships between components of biomolecular pathways and networks - is a primary goal of omics datasets in molecular biology studies. Generally, observing statistical association between network components does not demonstrate causality. However, we can safely use statistical association observed in measurements generated by a sound experimental design as evidence for the presence of a causal relation.

High-throughput omics technologies enable large-scale experiments, with simultaneous measurements of multiple cellular components in a sample. The huge amount of data generated paradoxically make the task of causal inference much more difficult, because, when many associations are examined, some will appear significant just by chance. In other words, large-scale experiments are more prone to hiding the true signal and generating spurious associations, leading to increased false positive conclusions that causal relationships are present. This problem can be addressed by improving experimental design and/or refining the biological question. Below, we describe the process of elucidating statistical associations from data and suggest practical approaches for analysis of large scale datasets.

Statistical inference
In MAPK signaling, Raf causally affects active Mek levels (via phosphorylation), while Mek causally affects Erk. Imagine this relationship was unknown: could it be detected from measurements of these phosphoproteins?  Given sufficient data, a correlation will be detected between each pair of proteins, due to (direct and indirect) causal relationships. Figure 1, top panel, depicts these correlation as black lines, causal relationships are depicted as blue arrows.  The edge linking Raf to Erk is not causal, because Raf’s effect on Erk occurs only via Mek (and that affect is already represented, rendering the Raf-Erk edge superfluous). Can we use a statistical trick to eliminate this noncausal edge?

First, some terminology.  A statistical association (such as a correlation) between two variables indicates that they are dependent. Sometimes we choose to assess a dependence in the context of the value of a third variable, in this case the dependence is called conditional dependence, ie because it is conditioned on the third variable. Let’s see how this applies here, by examining the dependence between Raf and Erk.  If we condition on Mek, then we assume that we know the value of Mek: perhaps we select only samples which have a high level of Mek, so Mek is fixed at level “high”.  Can the dependence between Raf and Erk still be detected?  If, due to noise, some of these Mek=high samples have an intermediate or even low level of Raf, will Erk be correspondingly low?  Based on the causal mechanism, Erk will more closely follow Mek, since Mek is its causal parent.  Because of that, the Raf-Erk dependence, once conditioned on Mek, will be reduced or eliminated, thus indicating that the Raf-Erk edge can be removed.  Using this approach, it is possible to keep only the causal edges as depicted by the black lines in Figure 1, bottom panel.

So far in this toy example, the causal edges have been found, but their causal direction has not been revealed.  The most powerful technique for finding edge directionality is, quite naturally, perturbations, such as small molecule inhibitors.  An intervention on Mek for instance reveals the causal edge direction from Mek to Erk.  The Raf-->Mek edge is automatically revealed for two reasons: First, because Raf is not affected (or not affected strongly) by Mek inhibition, and secondly, because once one edge in this triplet is oriented, the second is automatically oriented by statistical properties of the structure, given certain assumptions.  These properties are beyond the scope of this discussion (see … my thesis or a thousand other places) for a description.  Suffice to say that while perturbations are very useful for orienting edges, it is happily not necessary to perform exhaustive perturbations in order to assess causal directions.

<figure>
  <img src="http://i.imgur.com/Ft2exsrl.png" alt="Mapk" width="304" height="228">
  <figcaption>Fig1. In the MAPK signaling pathway, Raf regulates Mek, which regulates Erk.
  Top; the lines represent associate - the activity of the kinases on this pathway are all correlated. Bottom: the lines represent conditional dependence, there is no conditional dependence edge from Raf to Erk because given you know Mek, knowing Raf tells you nothing about Erk. They are conditionally independent.</figcaption>
</figure>

Fig1. In the MAPK signaling pathway, Raf regulates Mek, which regulates Erk. Top; the lines represent associate - the activity of the kinases on this pathway are all correlated. Bottom: the lines represent conditional dependence, there is no conditional dependence edge from Raf to Erk because given you know Mek, knowing Raf tells you nothing about Erk. They are conditionally independent.

We use algorithms borrowed from the causal Bayesian network modeling domain to do causal inference in the context of an experiment with multiple intercorrelated response variables. These algorithms’ approaches vary but they essentially do two things; (1) find cases of conditional independence and reduce the dense set of pairwise associations to a sparse set of conditional dependencies, (2) use the experiment’s intervention information to evaluate those conditional dependencies as evidence for potential causal relations.

II. Inference with large numbers of variables

The challenge with large datasets is the large number of variables, which increase the number of spurious statistical associations, and thus the number of spurious cases of conditional dependence, and the number of incorrect conclusions of the presence of a causal relation. To illustrate, we ran a simulation where first simulate a 20 features dataset each with a 100 Gaussian random measurements, then increase the number of features to 500. In each case the features are completely independent. This means if we quantify association using Pearson correlation, any correlation we find will be completely spurious. We record the maximum correlation between the 20 feature set and the 500 feature set. We repeat this simulation 500 times.

```{r, echo=FALSE, eval=FALSE}
set_20 <- rep(0, 500)
set_500 <- rep(0, 500)
for(i in 1:500){
  x <- matrix(rnorm(100 * 20), ncol = 20)
  cor_x <- cor(x)
  diag(cor_x) <- 0
  set_20[i] <- max(cor_x)
  y <- matrix(rnorm(100 * 500), ncol = 500)
  cor_y <- cor(y)
  diag(cor_y) <- 0
  set_500[i] <- max(cor_y)
}
hist(set_500, col = rgb(0.1,0.1,0.1,0.5), xlab = NULL, xlim = c(min(set_20) , max(set_500) + .1 ), 
     main = "Highest Spurious Correlation")
hist(set_20, col = rgb(0.8,0.8,0.8,0.5), add = TRUE)
legend("topr", legend=c("20 features", "500 features"), cex = c(.5),  lwd=c(4,4), col=c(rgb(0.8,0.8,0.8,0.5), rgb(0.1,0.1,0.1,0.5)))
```

<figure>
  <img src="http://i.imgur.com/CSuQdePl.png" alt="spurious1">
  <figcaption>Fig2. As you increase the number of features, you get more high scoring spurious correlations. </figcaption>
</figure>

The increased incidence of spurious correlation means increased false positives in detecting conditional dependence relationships. To illustrate, we repeat the previous simulation, except now expanding from 20 to only 100 features. In each of the 500 instances, we apply a search algorithm that iteratively performs conditional independence tests, returning a count of detected conditional dependence relationships. As before, since we simulated independent features, any conditional dependence relationship reported by this algorithm is false.


```{r, echo=FALSE, eval = FALSE}
library(bnlearn)
set_20 <- rep(0, 500)
set_100 <- rep(0, 500)
for(i in 1:length(set_20)){
  print(i)
  x <- as.data.frame(matrix(rnorm(100 * 20), ncol = 20))
  set_20[i] <- narcs(gs(x, undirected = TRUE))
  y <- as.data.frame(matrix(rnorm(100 * 100), ncol = 100))
  set_100[i] <- narcs(gs(y, undirected = TRUE))
}
hist(set_100, col = rgb(0.1,0.1,0.1,0.5), xlab = NULL,  xlim = c(min(set_20), max(set_100)), 
     main = "Spurious Conditional Dependence Relationships")
hist(set_20, col = rgb(0.8,0.8,0.8,0.5), add = TRUE)
legend("top", legend=c("20 features", "100 features"), cex = c(.5),  lwd=c(4,4), col=c(rgb(0.8,0.8,0.8,0.5), rgb(0.1,0.1,0.1,0.5)))
```

<figure>
  <img src="http://i.imgur.com/GzfGjio.png" alt="spurious conditional dependence" width="304" height="228">
  <figcaption>Fig3. Increasing the number of measured features means increasing the false positive detection of conditional dependence.</figcaption>
</figure>

III. Inferring causality from omics experiments

These simulations demonstrate that many variables (may) give many false results, rendering the problem of finding true connections relatively difficult.  Fortunately, there are ways to address this problem, these Causality Inference in Omics tools are listed below:
 1) Measure many samples.  If feasible, high throughput measurements that measure many samples (not just many variables) provide the statistical power to tell spurious associations from true associations.  Think of a correlation plot showing just 4 dots.  Even if they line up fairly well, they will not convincingly show a correlation.  In contrast, 400 samples showing a correlation provide ample evidence.  This intuition underlies the use of single cell data for causal modeling, as we described previously (self citation ! :-P
 
2) Refine the problem, thus limiting the variable number.  If the biological system in question is sufficiently well studied, it might be possible to ask specific questions of the data, such as ascertaining the presence or absence of a particular edge or pathway, or assessing connections to a particular protein.  The more specific the question, the less data is needed overall to make solid statistical inferences.  

3) Employ perturbations, especially ones relevant to the biological question under study.  Perturbations are invaluable in finding causal directions but also help to determine which variables may be important to include in statistical analyses.

4) Use prior knowledge, not just from experts but also from noisier sources.  This approach uses pathway databases such as KEGG to answer the questions;  

i) What causal relations are we sure exist? 
ii) What causal relations are we sure do not exist? 
iii) What causal relations do we expect to exist/not to exist?

In the context of this ‘weak’ evidence, it becomes much easier to constrain the problem of causal inference and learn more reliable relationships.

IV. Winning workflows

The Causality in Omics tool list above provides impactful approaches that can drastically improve causal inference from omics datasets, by constraining the inference task, rendering it much smaller, and thus allowing for accurate statistical inferences.  For instance, the task of assessing which of all the possible KEGG pathways is present in my dataset is a far smaller (thus easier) task statistically speaking than the task of assessing which random paths among any measured variables exist in my dataset.

How should the tools listed be used?  They are most powerful when used in combination, and in fact the lines between them are somewhat arbitrary and frequently blurred.  For instance, tool #3 calls for use of perturbations, but this task itself is complicated by large scale data, as the number of possible perturbations grows and experiments quickly become infeasible. Tool 4, prior biological knowledge, can be used to prioritize what to target with that limited set of interventions.  For example, if proteins a candidate drug is likely to impact are known, then interventions could target those proteins and those known a priori to interact with them, in order to acquire data that elucidates the mechanism of action for that drug.  

Effective workflows will resemble Mr Potato Head with these tools as components, and may be used iteratively.  [OK I just wanted to entertain you guys with that image.
Here I think we can wrap up, or we can list a few more tantalizing workflow suggestions with accompanying examples. Ie profer some workflow templates.  I’m not sure if that’s valuable or not]

signing off..
Karen :)
