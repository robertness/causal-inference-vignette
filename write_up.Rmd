---
title: "Distilling Causality from Correlation in Large-scale Omics Datasets"
author: "Robert Ness"
date: "September 3, 2015"
output: html_document
---

Our goal in molecular cell biology is causal inference -- meaning uncovering the regulatory relationships between components of the cell that determine phenotype and disease states.  Generally observing statistical association between such components does not demonstrate causality.  However, we can safely use statistical association observed in measurements generated by a sound experimental design as evidence for the presence of a causal relation.  

High-throughput omics technologies enable us to conduct large-scale experiments, where we simultaneously measure multiple cellular components in a sample, and in many cases acquire a large amount of data for each component.  However, despite generating much more data, these large-scale experiments make the task of causal inference much more difficult.  Large-scale experiments are more prone to hiding the true signal and generating spurious associations, leading to increased false positive conclusions that causal relationships are present.  We can address this problem by improving our experimental design.

## How we infer causality from omics experiments

The MAPK signaling pathway proteins Mek and Erk have a cause-and-effect relationship; Mek has a causal impact on Erk. The causal mechanism is phosphorylation, Mek phosphorylates Erk.  

Assuming this causal relation were not known, the question of whether Mek has a causal effect on Erk is evaluated with a designed experiment, where Mek is the treatment and Erk is the response.  Intervention and randomization are key parts of the experimental design.  Intervention means we target the potential cause, Mek, and fix it at different levels, for example 'high activity' and 'baseline activity'.  Randomization refers to random assignment of samples or subjects to each of these levels, helping to alleviate bias introduced by unseen factors.  The experiment generates measurements that will show a strong statistical association between Mek and Erk.  Intervention and randomization enable us to interpret that statistical association as evidence for Mek's causal influence on Erk.

With omics technologies, instead of measuring one response, we simultaneous measure many.  Instead of one statistical association to evaluate, the measurements contain many pairwise associations between each of the measured features.  

As with the simple one-response experimental design, we seek to use these associations to evaluate the presence of causal relations.  Saying two objects have a statistical association is the same as saying they are not statistically independent.  However, they can still be conditionally independent, meaning the association disappears conditional on knowing what all the other components in the system are doing. Figure 1 illustrates this principle with the MAPK proteins.

<figure>
  <img src="http://i.imgur.com/Ft2exsrl.png" alt="Mapk" width="304" height="228">
  <figcaption>Fig1. In the MAPK signaling pathway, Raf regulates Mek, which regulates Erk.
  Top; the lines represent associate - the activity of the kinases on this pathway are all correlated. Bottom: the lines represent conditional dependence, there is no conditional dependence edge from Raf to Erk because given you know Mek, knowing Raf tells you nothing about Erk. They are conditionally independent.</figcaption>
</figure>

We use algorithms borrowed from the causal Bayesian network modeling domain to do causal inference in the context of an experiment with multiple intercorrelated response variables.  These  algorithms' approaches vary but they essentially do two things; (1) find cases of conditional independence and reduce the dense set of pairwise associations to a sparse set of conditional dependencies, (2) use the experiment's intervention information to evaluate those conditional dependencies as evidence for potential causal relationtions.  

The challenge with large datasets is that by measuring more things, we increase the number of spurious statistical associations, and thus the number of spurious cases of conditional dependence, and thus the number of incorrect conclusions of the presence of a causal relation.  To illustrate, we ran a simulation where first simulate a 20 features dataset each with a 100 Gaussian random measurements, then increase the number of features to 500.  In each case the features are completely independent.  This means if we quantify association using Pearson correlation, any correlation we find will be completely spurious.  We record the maximum correlation between the 20 feature set and the 500 feature set. We repeat this simulation 500 times.

```{r, echo=FALSE, eval=FALSE}
set_20 <- rep(0, 500)
set_500 <- rep(0, 500)
for(i in 1:500){
  x <- matrix(rnorm(100 * 20), ncol = 20)
  cor_x <- cor(x)
  diag(cor_x) <- 0
  set_20[i] <- max(cor_x)
  y <- matrix(rnorm(100 * 500), ncol = 500)
  cor_y <- cor(y)
  diag(cor_y) <- 0
  set_500[i] <- max(cor_y)
}
hist(set_500, col = rgb(0.1,0.1,0.1,0.5), xlab = NULL, xlim = c(min(set_20) , max(set_500) + .1 ), 
     main = "Highest Spurious Correlation")
hist(set_20, col = rgb(0.8,0.8,0.8,0.5), add = TRUE)
legend("topr", legend=c("20 features", "500 features"), cex = c(.5),  lwd=c(4,4), col=c(rgb(0.8,0.8,0.8,0.5), rgb(0.1,0.1,0.1,0.5)))
```

<figure>
  <img src="http://i.imgur.com/CSuQdePl.png" alt="spurious1">
  <figcaption>Fig2. As you increase the number of features, you get more high scoring spurious correlations. </figcaption>
</figure>

The increased incidence of spurious correlation means increased false positives in detecting conditional dependence relationships.  To illustrate, we repeat the previous simulation, except now expanding from 20 to only 100 features. In each of the 500 instances, we apply a search algorithm that iteratively performs conditional independence tests, returning a count of detected conditional dependence relationships.  As before, since we simulated independent features, any conditional dependence relationship reported by this algorithm is false.

```{r, echo=FALSE, eval = FALSE}
library(bnlearn)
set_20 <- rep(0, 500)
set_100 <- rep(0, 500)
for(i in 1:length(set_20)){
  print(i)
  x <- as.data.frame(matrix(rnorm(100 * 20), ncol = 20))
  set_20[i] <- narcs(gs(x, undirected = TRUE))
  y <- as.data.frame(matrix(rnorm(100 * 100), ncol = 100))
  set_100[i] <- narcs(gs(y, undirected = TRUE))
}
hist(set_100, col = rgb(0.1,0.1,0.1,0.5), xlab = NULL,  xlim = c(min(set_20), max(set_100)), 
     main = "Spurious Conditional Dependence Relationships")
hist(set_20, col = rgb(0.8,0.8,0.8,0.5), add = TRUE)
legend("top", legend=c("20 features", "100 features"), cex = c(.5),  lwd=c(4,4), col=c(rgb(0.8,0.8,0.8,0.5), rgb(0.1,0.1,0.1,0.5)))
```

<figure>
  <img src="http://i.imgur.com/GzfGjio.png" alt="spurious conditional dependence" width="304" height="228">
  <figcaption>Fig3. Increasing the number of measured features means increasing the false positive detection of conditional dependence.</figcaption>
</figure>

Lastly, measuring more things also adversely effects the selection of interventions in the design.  The more components of the cell you measure, the more interventions you need to target those components.  This, of course, increases the cost of the experiment.  Under constrained resources, we can use a limited set of interventions that will partially elucidate causality in the system.  We use prior biological knowledge to prioritize what to target with that limited set of interventions.  For example, if we know what proteins a candidate drug is likely to impact, then interventions should target those proteins and those known a priori to interact with them, in order to acquire data that elucidates the mechanism of action for that drug.  

## Use of prior biological knowledge to address the spurious association problem

Similarly, we can use to prior biological knowledge to address the spurious association problem and improve detection of conditional dependence relationships.  Specifically, this approach uses pathway databases such as KEGG to answer the questions;  

1) What causal relations are we sure exist? 
2) What causal relations are we sure do not exist? 
3) What causal relations do we expect to exist/not to exist?

Answering these questions enables us to improve the search for conditional dependence relations, minimizing false positives do to spurious associations.
  