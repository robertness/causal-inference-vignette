---
title: "Large-scale Omics Experiments are not Conducive to Causal Inference"
date: "September 3, 2015"
output: html_document
---

Causal inference â€“ the task of uncovering regulatory relationships between components of biomolecular pathways and networks - is a primary goal of omics datasets in molecular biology studies. Large-scale experiments are fishing expeditions, where we look for associations. However, the associations provided by this type of experiment are not conducive to finding causal relationships. 

The goal of this manuscript is to highlight how large-scale experiments can impede the quest to uncovering the causal mechanism that determines the biology, and provide suggestions for addressing this problem through better experimental design and refining the biological question. We illustrate this on the MAPK pathway.

## Increasing the number of measured features decreases the ability to infer causality

In MAPK signaling, Raf causally affects active Mek levels (via phosphorylation), while Mek causally affects Erk. Imagine these relationships were unknown: could it be detected from measurements of these phosphoproteins?  If we took an arbitrary biological sample and simultaneously quantified Raf, Mek, and Erk, we'd find Raf-Mek, Mek-Erk, and Raf-Erk correlations, due their direct and indirect causal relationships. 

To get from correlation to causality, we need a controlled experiment.  Based on the Mek-Erk correlation, we can design an experiment based on the hypothesis that Mek has a causal influence on Erk.  In the experiment, we'd *intervene* in Mek, meaning we'd artificially control Mek at different levels of phospho-activity (for example with a small molecule treatment that inhibits Mek), then randomly assign cell lines to each of these levels.  In doing so we'd control for confounding factors and free ourselves to interpret the correlation between Mek levels and Erk measurements as evidence for the presence of causal influence of Mek on Erk.  Indeed, if our intervention targeted Erk and we observed Mek, the measured correlation would be very weak since the Erk->Mek causal relationship doesn't exist.

Now, suppose you have access to a technology that can simultaneously quantify several thousands of phosphoproteins, including Raf, Mek and Erk.  As is typical with such large-scale experiments, you only have a very small number of interventions, and maybe 3 replicates.  Even if those interventions targeted Raf, Mek, or Erk, there would be so much spurious correlation between these phosphoproteins and all the others you mentioned that causal inference would be infeasible.

To explain why, we need to introduce some terminology.  A statistical association (such as Pearson correlation) between two measured entities indicates that they are dependent. Sometimes we choose to assess the dependence in the context of already knowing what other key components of the system are doing.  In this case the dependence is called *conditional dependence*, because we evaluate the association conditional on the states of other components in the system.  

We can see how this applies here by examining the dependence between Raf and Erk.  Figure 1, top panel, depicts the correlation between Raf, Mek, and Erk as black lines, causal relationships are depicted as blue arrows.  If we condition on Mek, then we assume that we know what Mek is doing.  In all the measurements where Mek is high, can the dependence between Raf and Erk still be detected?  Since Mek is directly upstream of Erk, knowing Mek tells us all there is to know about Erk, and knowing Raf tells us nothing.  Because of that, the Raf-Erk dependence, once we condition on Mek, will be reduced or eliminated, thus indicating that the Raf-Erk edge can be removed.  Using this approach, it is possible to keep only the conditional dependence edges as depicted by the black lines in Figure 1, bottom panel.  Conditional dependence is important because, under certain assumptions, we can move from conditional dependence to causal influence by applying interventions.  

<figure>
  <img src="http://i.imgur.com/Ft2exsrl.png" alt="Mapk" width="304" height="228">
  <figcaption>
  Fig1. In the MAPK signaling pathway, Raf regulates Mek, which regulates Erk. Top; the lines represent association - the activity of the kinases on this pathway are all correlated. Bottom: the lines represent conditional dependence, there is no conditional dependence edge from Raf to Erk because given you know Mek, knowing Raf tells you nothing about Erk. They are conditionally independent.
  </figcaption>
</figure>

Computational methods that do causal inference in the context of an experiment that simultaneously measures multiple intercorrelated response variables all essentially have the same two step process; (1) reduce the dense set of pairwise associations to a sparse set of conditional dependencies, (2) use information about the interventions included in the experiment to evaluate those conditional dependencies as evidence for potential causal relations.

The problem of doing causal inference with large-scale experiments is two-fold.  Firstly, sample size is typically far too small for the large number of features we measure.  With the large-scale experiment described above, it is clear that viewing a scatter-plot between a pair of features that has only 3 points is uninformative -- even if the points correlated perfectly, 3 points is not enough to conclude anything about the relationship with any confidence.  But even with hundreds of samples, we are still plagued by spurious associations when the number of features is so large, since more features means greater chance associations will occur at random.

To illustrate, we ran a simulation where we first simulate a 20 features dataset each with a 100 Gaussian random measurements, then increase the number of features to 500. In both cases the features are completely independent. This means if we quantify association using Pearson correlation, any correlation we find will be completely spurious. We record the maximum correlation between the 20 feature set and the 500 feature set. We repeat this simulation 500 times.

```{r, echo=FALSE, eval=FALSE}
set_20 <- rep(0, 500)
set_500 <- rep(0, 500)
for(i in 1:500){
  x <- matrix(rnorm(100 * 20), ncol = 20)
  cor_x <- cor(x)
  diag(cor_x) <- 0
  set_20[i] <- max(cor_x)
  y <- matrix(rnorm(100 * 500), ncol = 500)
  cor_y <- cor(y)
  diag(cor_y) <- 0
  set_500[i] <- max(cor_y)
}
hist(set_500, col = rgb(0.1,0.1,0.1,0.5), xlab = NULL, xlim = c(min(set_20) , max(set_500) + .1 ), 
     main = "Highest Spurious Correlation")
hist(set_20, col = rgb(0.8,0.8,0.8,0.5), add = TRUE)
legend("topr", legend=c("20 features", "500 features"), cex = c(.5),  lwd=c(4,4), col=c(rgb(0.8,0.8,0.8,0.5), rgb(0.1,0.1,0.1,0.5)))
```

<figure>
  <img src="http://i.imgur.com/CSuQdePl.png" alt="spurious1">
  <figcaption>Fig2. As you increase the number of features, you get more high scoring spurious correlations. </figcaption>
</figure>

The increased incidence of spurious correlation means increased false positives in detecting conditional dependence relationships. To illustrate, we repeat the previous simulation, except now expanding from 20 to only 100 features. In each of the 500 instances, we apply a search algorithm that iteratively performs conditional independence tests, returning a count of detected conditional dependence relationships. As before, since we simulated independent features, any conditional dependence relationship reported by this algorithm is a false positive, i.e. it doesn't actually exist in the mechanism that generated the data.


```{r, echo=FALSE, eval = FALSE}
library(bnlearn)
set_20 <- rep(0, 500)
set_100 <- rep(0, 500)
for(i in 1:length(set_20)){
  print(i)
  x <- as.data.frame(matrix(rnorm(100 * 20), ncol = 20))
  set_20[i] <- narcs(gs(x, undirected = TRUE))
  y <- as.data.frame(matrix(rnorm(100 * 100), ncol = 100))
  set_100[i] <- narcs(gs(y, undirected = TRUE))
}
hist(set_100, col = rgb(0.1,0.1,0.1,0.5), xlab = NULL,  xlim = c(min(set_20), max(set_100)), 
     main = "Spurious Conditional Dependence Relationships")
hist(set_20, col = rgb(0.8,0.8,0.8,0.5), add = TRUE)
legend("top", legend=c("20 features", "100 features"), cex = c(.5),  lwd=c(4,4), col=c(rgb(0.8,0.8,0.8,0.5), rgb(0.1,0.1,0.1,0.5)))
```

<figure>
  <img src="http://i.imgur.com/GzfGjio.png" alt="spurious conditional dependence" width="304" height="228">
  <figcaption>Fig3. Increasing the number of measured features means increasing the false positive detection of conditional dependence.</figcaption>
</figure>

As you increase the number of features you measure, the number of false positive detection of conditional dependence explodes.  What this means is that the computational methods for causal inference will fail for the typical large-scale experiment, because when their input data contains a large amount of features relative to sample size, they cannot reliably detect the conditional dependence relationships they need to infer causality.

The second problem is that the aforementioned computational methods require interventions to to infer causality.  To infer the causal relationships between many measured features, you need many interventions targeting those many features.  Thousands of interventions targeting thousands of features is infeasible.  

## Experimentalists can apply heuristics for causal inference in large-scale omics data

Fortunately, there are ways to address this problem, these *Causality Inference in Omics* heuristics are listed below:

1) Measure many samples.  If feasible, high throughput measurements that measure many samples (not just many features) provide the statistical power to tell true associations from spurious associations.  This intuition motivates the use of single cell data for causal modeling, where having many thousands of cells per sample provides statistical power.
 
2) Refine the problem, thus limiting the number of features.  If the biological system in question is sufficiently well-studied, it might be possible to ask specific questions of the data, such as ascertaining the presence or absence of a particular edge or pathway, or assessing connections to a particular protein.  The more specific the question, the less data is needed overall to make solid statistical inferences.  

3) Use prior knowledge, not just from experts but also from noisier sources.  Based on information in  pathway databases such as KEGG, answer the questions;  

i) What causal relations are we sure exist? 
ii) What causal relations are we sure do not exist? 
iii) What causal relations do we expect to exist/not to exist?

Such questions can be answered with a variety of biological knowledge.  For example, we know more about causal relations between phosphoproteins known to cluster together spatially within the cell, and be more interested in learning about signaling mechanisms that cross compartments inside the cell. By answering these questions, we can bias the application of computational causal inference questions such that they focus less on conditional dependence and causal relations we know to exist and more towards the novel causal information hidden in the data.  

4) Employ interventions selectively.  Some interventions are 'fat-handed', in that they perturb many features in the system, providing more causal inference bang for your intervention buck.  At the same time, targeted interventions are more useful for gaining mechanistic insight into the biological question under study.  For example, if proteins a candidate drug is likely to impact are known, then interventions could target those proteins and other proteins known a priori to interact with them, in order to acquire data that elucidates the mechanism of action for that drug.  

The Causality in Omics tool list above provides impactful approaches that can drastically improve causal inference from omics datasets, by constraining the inference task, rendering it much smaller, and thus allowing for accurate statistical inferences.  For instance, the task of assessing which of all the possible KEGG pathways is present in my dataset is a far smaller (thus easier) task statistically speaking than the task of assessing which of all possible combinations of my measured features might form a biological pathway.

How should the tools listed be used?  They are most powerful when used in combination, and in fact the lines between them are somewhat arbitrary and frequently blurred.  For instance, tool #4 calls for use of interventions, but this task itself is complicated by large scale data, as the number of possible perturbations grows and experiments quickly become infeasible. Tool 3, prior biological knowledge, can be used to prioritize what to target with that limited set of interventions.  

