<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title> Large-scale experiments are more prone to hiding the true signal and generating spurious associations; therefore right perturbations and prior knowledge are key to infer causality.</title>
<style type="text/css">
    li { list-style: none;  margin: 0; }
    p { margin: 0; }

    span.l { color: red; font-weight: bold; }

    a.mapnode:link {text-decoration: none; color: black; }
    a.mapnode:visited {text-decoration: none; color: black; }
    a.mapnode:active {text-decoration: none; color: black; }
    a.mapnode:hover {text-decoration: none; color: black; background: #eeeee0; }

</style>
<!-- ^ Position is not set to relative / absolute here because of Mozilla -->
</head>
<body>
<p> Large-scale experiments are more prone to hiding the true signal and generating spurious associations; therefore right perturbations and prior knowledge are key to infer causality.
<ul><li><p>How to infer causality from experiments.
<ul><li><p>By incorporating randomization into the design of a typical experiment, we can evaluate a possible causal relationship between a treatment (cause) and phenotype (effect). &nbsp;However, in systems biology, inferring causality means inferring from experimental measurements the set of regulatory interactions that connect the treatment to the phenotype.
<p>The gold standard methods for inferring causal relationships between simulateously measured features in an experiment is a two step process; first determine what features are conditionally dependent, then determine the causal relationships between conditionally dependent features.
<ul><li>Conditional dependence
<ul><li><p>When we simultaneously measure several components within a cell, the measurements will be strongly correlated.
<p>However, many correlated pairs will be conditionally independent, meaning the correlation and other statistical associations between two components disappear when we know what other components in the system are doing.
<ul><li>Karen's MAPK example with introduction of causal semantics
<ul><li><p>Mek -&gt; Erk means &nbsp;increasing the concentration of phosphorylated Mek will cause an increase in the concentration of phosphorylation of Erk by means of Mek's phosphorylation of Erk. 
<p>Iintuitive on/off shorhand: Mek -&gt; Erk means Mek being &nbsp;"on" will 'turn on' Erk
</li>
</ul>
</li>
<li>Karen's Simpsons example

</li>

</ul><p>Methods for finding causal relationships in algorithmically determine conditional independencies in the hairball of correlations. &nbsp;The result set of conditional dependencies far sparser than the original set of correlations.
</li>
</ul>
</li>
<li>Determining causality
<ul><li><p>Assuming we measure everything, if two components are conditionally dependent, there are 3 possibilities. &nbsp;A causes B, B causes A, or A and B both cause C.
<ul><li><p>The MAPK example illustrates the first two cases. &nbsp;Given we find Mek and Erk are conditionally dependent, &nbsp;Mek -&gt; Erk , or Erk -&gt; Mek. &nbsp;
<p>The third case could be a case where either kinase A or kinase B independently phosphorylate C. &nbsp;In this case, if we know C is on, then A and B are conditional dependent because one of them must of activated C, so knowing A is off tells us that B must be on.
</li>
</ul><p>Treatments called perturbations elucidate causal influence between two conditionally dependent objects
<ul><li><p>Perturbations fix the value of one object, so we can observe whether the other responds. &nbsp;In systems biology, this means changing the abundance of a specific object. &nbsp;An example is genetic knockouts.
<p>Perturbations can also block the ability of an object to influence others. &nbsp;An example is small molecule inhibitors which can stop a kinase from phosphorylating its target without affecting the abundance of the kinase. 
</li>
</ul><p>Note that we can never be sure we measure everything, so we treat an inferred causal relationship as a hypothesis that requires validation in a follow up experiment.
</li>
</ul>
</li>

</ul><p>We use these gold standard methods construct a causal Bayesian network.
<ul><li><p>A Bayesian network is a probabilistic graphical model (a type of statistical model) that represents a set of random variables and their conditional dependencies via a directed acyclic graph (DAG).
<p>A causal Bayesian network (or simply causal network) is a Bayesian network where the direction of the edges represent causal influence.
<p>In the context of systems biology, we use the causal model formalism to represent the regulatory relationships between genes and gene products within a cell. &nbsp;Tracing the edges in a causal biological model shows how signal flows through the system.
</li>
</ul></li>
</ul><p>Large-scale experiments have higher degree of spurious correlation. &nbsp;This makes the task of distilling conditional dependence relationships from the space of correlations more difficult
<ul><li><p>Variation of Olga's spurious correlations simulation. &nbsp;In one instance sim from an MVN with p orthogonal dimensions. &nbsp;Search for conditional dependencies using BIC penalty. &nbsp;Plot the histogram of max correlation between features, and the histogram of the total number of false conditional dependence relationships detected. &nbsp;Increase p by an order of magnitude and repeat. &nbsp;Overlay second 2 histograms on the first
<p>High correlatipn encourages false assumptions of causality -- Olga's figures
</li>
</ul><p>There are two approaches to addressing this issue; incorporating prior biological knowledge and adding perturbations to the experiment.
<ul><li>Incorporating prior knowledge: demonstrate on real or sim measurements on a signaling pathway
<ul><li><p>Start the search for conditional dependencies with a starting set of conditional dependencies already &nbsp;in KEGG
<p>Show the performance of additional conditional dependence and causal relationships is improved.
<p>Ideally show on a phospho signaling dataet
<p>Alternatively on simulated data.
</li>
</ul>
</li>
<li>Incorporating perturbations: &nbsp;demonstrate on sim measurements of a gene regulatory network
<ul><li><p>Start with high number of features, no perturbations. &nbsp;Do causal structure inference, evaluate performance of structure inference against ground truth. 
<p>Add in a set of perturbations, repeat
<p>Repat, show each time that perforance improved
</li>
</ul>
</li>
<li>Combine both approaches

</li>

</ul><p>Open problems in experimental design and statistical modeling
<ul><li><p>Proposed workflow: Large scale -&gt; CyTOF -&gt; Validation scale. &nbsp;
<ul><li><p>We can possibly use large scale data to determine what to measure in the CyTOF
<p>It is possible we could use large scale date to infer conditional dependences, and use that, along with prior knowledge to design a minimal/optimal set of perturbations for CyTOF step
</li>
</ul><p>What is the ideal perturbation type; &nbsp;knockouts, activations, inhibitions
<p>In CyTOF, having multiple cell level replicates is not the same as having biological replications. &nbsp;We need an experimental design that enables causal inference with cell level replicates, nested in biological replicates.
</li>
</ul></li>
</ul></body>
</html>
